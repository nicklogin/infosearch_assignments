{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа\n",
    "## Ранжирование с помощью ML\n",
    "\n",
    "\n",
    "![](https://avatars.mds.yandex.net/get-research/1677227/2a00000168a82fc9b0eac19e430b8454a656/orig)\n",
    "\n",
    "\n",
    "Одна из отличительных особенностей задачи ранжирования от классических задач машинного обучения заключается в том, что качество результата зависит не от предсказанных оценок релевантности, а от порядка следования документов в рамках конкретного запроса, т.е. важно не абсолютное значение релевантности (его достаточно трудно формализовать в виде числа), а то, более или менее релевантен документ, относительно других документов.\n",
    "\n",
    "### Подходы к решению задачи ранжирования\n",
    "Существуют 3 основных подхода к ранжированию, различие между которыми заключается в том, на какую функцию потерь они опираются:\n",
    "  \n",
    "1. **Поточечный подход (pointwise)**. В этом подходе предполагается, что каждой паре запрос-документ поставлена в соответствие численная оценка. Задача обучения ранжированию сводится к построению регрессии: для каждой отдельной пары запрос-документ необходимо предсказать её оценку.\n",
    "\n",
    "2. **Попарный подход (pairwise)**. В таком подходе обучение ранжированию сводится к построению бинарного классификатора, которому на вход поступают два документа, соответствующих одному и тому же запросу, и требуется определить, какой из них лучше. Другими словами, функция потерь штрафует модель, если отранжированная этой моделью пара документов оказалась в неправильном порядке.\n",
    "\n",
    "3. **Списочный подход (listwise)**. Его суть заключается в построении модели, на вход которой поступают сразу все документы, соответствующие запросу, а на выходе получается их перестановка.\n",
    "\n",
    "\n",
    "Будем использовать самый простой подход - поточечный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка качества\n",
    "\n",
    "Для оценивания качества ранжирования найденных документов в поиске традиционно используется метрика *DCG* ([Discounted Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)) и ее нормализованный вариант — *nDCG*, всегда принимающий значения от 0 до 1.\n",
    "\n",
    "Для одного запроса DCG считается следующим образом:\n",
    "$$ DCG(Q) = \\sum_{i=1}^{numpos}\\frac{(2^{rel_i} - 1)}{\\log_2(i+1)}, $$\n",
    "где\n",
    ">$numpos$ — количество документов в поисковой выдаче, среди которых мы оценимваем качество (например, в предудыщих заданиях *num_pos* был равен 5)  \n",
    "$rel_i$ — оценка релевантности документа, находящегося на i-той позиции   \n",
    "   \n",
    "\n",
    "Нормализованный вариант *nDCG* получается делением *DCG* на максимальное из его значений:\n",
    "\n",
    "$$nDCG = \\frac{DCG}{IDCG} \\in [0, 1].$$\n",
    "> *IDCG* — наибольшее из возможных значение *DCG* \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Чтобы оценить значение *nDCG* на выборке $Queries$ ($nDCG_{Queries}$) размера $N$, необходимо усреднить значение *nDCG* по всем запросам  выборки:\n",
    "$$nDCG_{Queries} = \\frac{1}{N}\\sum_{q \\in Queries}nDCG(q).$$\n",
    "\n",
    "Пример реализации метрик ранжирование на python можно найти [здесь](https://gist.github.com/mblondel/7337391)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Погнали\n",
    "###  **Задача: предсказать оценку релевантности для запросов тестового датасета**\n",
    "\n",
    "\n",
    "Мы будем работать на данных с конкурса [Интернет-математика 2009](https://academy.yandex.ru/events/data_analysis/grant2009/). По ссылке можно прочитать описание данных.      \n",
    "\n",
    "Данные\n",
    "> Данные разбиты на две выборки – обучающая выборка imat2009_learning.txt с известными оценками близости запроса и документа и тестовая выборка с неизвестными близостями imat2009_test.txt  \n",
    "\n",
    "Обучающая выборка\n",
    "> Данные для обучения содержат **97 290 строк**, которые соответствуют **9 124 запросам**  \n",
    "Каждая строка соответствует паре «запрос-документ»    \n",
    "\n",
    "Признаки\n",
    ">Каждой паре «запрос-документ» соответствуют значения **245 признаков**. Формат хранения feat_num:value. Если значение признака равно 0, то он опускается.     \n",
    "В комментариях в конце каждой строки указан **идентификатор запроса**.   \n",
    "Файл с обучающей выборкой содержит **оценку релевантности**, значения из диапазона **[0, 4]** (4 – «высокая релевантность», 0 – «нерелевантно»).   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TRAIN DATA\n",
    "file_learning = 'imat2009_learning.txt'\n",
    "\n",
    "with open(file_learning) as f:\n",
    "    train_data = f.readlines()\n",
    "    \n",
    "    \n",
    "# LOAD TEST DATA\n",
    "file_test = 'imat2009_test.txt'\n",
    "\n",
    "with open(file_test) as f:\n",
    "    test_data = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97290, 115643)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура данных следующая - первый элемент в строке - это оценка близости запроса и документа, дальше идут признаки документа, а последний элемент строки - это id запроса:\n",
    "\n",
    "> RELEVANCE      feature:value feature:value ... feature:value     # QUERY_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 1:0.000023 7:0.704953 8:0.550315 9:0.032294 11:0.712631 14:0.015686 15:0.137255 16:0.302576 17:1.000000 18:0.996078 22:1.000000 23:1.000000 24:1.000000 27:0.700000 28:0.587629 29:0.999881 30:0.032294 34:0.000023 36:0.431373 37:0.002247 38:0.054902 41:1.000000 46:0.002247 50:0.032294 51:0.325613 52:0.056641 53:0.820677 54:0.388235 55:0.450980 56:0.312547 57:0.004672 59:1.000000 61:0.000023 65:1.000000 68:0.712195 69:0.001400 70:1.000000 71:0.001013 73:0.709459 74:0.560784 76:0.142857 77:0.360800 78:1.000000 79:1.000000 80:1.000000 82:0.000023 83:1.000000 85:0.996078 86:0.070588 87:1.000000 88:0.999797 92:1.000000 93:0.714286 95:0.039216 97:0.000023 98:0.356490 99:0.165041 102:1.000000 103:1.000000 104:1.000000 105:0.486275 108:0.152941 120:0.996078 121:0.676507 122:0.032294 126:0.712980 128:0.121569 129:0.609261 132:1.000000 134:0.109804 135:0.030535 140:0.002247 142:0.698039 144:0.248111 145:0.356490 146:1.000000 147:0.498039 148:0.125490 150:0.704953 151:1.000000 152:0.098039 154:0.676507 156:0.066667 157:0.001470 160:0.101961 162:0.302576 165:0.843126 166:0.400000 167:0.019608 168:0.056641 171:1.000000 172:0.857143 177:0.285714 178:0.588235 179:0.820677 180:0.032294 181:0.196491 182:0.729730 185:0.756863 192:1.000000 193:1.000000 197:0.032294 202:0.310127 203:0.001186 205:1.000000 206:0.999835 209:0.291145 210:0.980392 211:0.960784 212:0.032294 213:0.000023 214:1.000000 216:0.999998 217:0.146074 219:0.300000 222:0.666667 224:0.145098 227:0.007089 228:1.000000 229:1.000000 230:0.032294 232:1.000000 233:0.494217 236:0.032749 243:0.000023 244:1.000000 245:0.000023 # 3382\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В test_data все оценки релевантности скрыты, поскольку этот набор данных использовался для проверки качества работы алгоритма в конкурсе. Нам эти данные не нужны, дальше работаем только с **train_data**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки качества будущей модели надо разбить обучающую выборку на обучение и валидацию в соотношении 70 / 30\n",
    "\n",
    "Внимание: разбивать необходимо **множество запросов QUERY_ID**, а не строчки датасета, чтобы в выборке находилась вся информация по запросу\n",
    "\n",
    "Для этого вам надо:\n",
    "1. собрать все запросы для каждого QUERY_ID\n",
    "\n",
    "```\n",
    "{\n",
    "query_id : [\n",
    "    RELEVANCE feature:value ... feature:value,\n",
    "    ...\n",
    "],\n",
    "...\n",
    "}\n",
    "```\n",
    "\n",
    "При этом я бы сразу собирала не сами данные, а номер строки в матрице данных\n",
    "```\n",
    "{\n",
    "query_id : [\n",
    "    line_num, line_num, ... line_num\n",
    "],\n",
    "...\n",
    "}\n",
    "```\n",
    "2. собрать матрицу данных, размер вектора равен числу признаков = 245\n",
    "```\n",
    "data = np.zeros((len(train_data), feats_num), dtype=np.float32) \n",
    "```\n",
    "\n",
    "3. собрать вектор с оценками релевантности, его размер равен размеру train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "\n",
    "labels = [] \n",
    "queries_lines_info = defaultdict(list) \n",
    "\n",
    "data = np.zeros((len(train_data), 245), dtype=np.float32)\n",
    "\n",
    "#YOUR CODE HERE\n",
    "query_id = re.compile(\"[0-9]+\\n$\")\n",
    "k_v_pair = re.compile(\"([0-9]+):(-?[0-9]+\\\\.?[0-9]+)\")\n",
    "\n",
    "\n",
    "for line_id, line in enumerate(train_data):\n",
    "    labels.append(int(line[0]))\n",
    "    q_id = int(query_id.search(line).group(0))\n",
    "    queries_lines_info[q_id].append(line_id)\n",
    "    for k, v in k_v_pair.findall(line):\n",
    "        data[line_id][int(k)-1] = float(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "assert data.shape == (len(train_data), 245)\n",
    "assert len(queries_lines_info.keys()) == 9124\n",
    "assert len(labels) == len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим запросы из *queries_lines_info.keys()* на обучающую *train_queries_ids* и валидационную выборки *test_queries_ids* (70/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#YOUR CODE HERE\n",
    "\n",
    "train_queries_ids, test_queries_ids = train_test_split(list(queries_lines_info.keys()),\n",
    "                                                       test_size=0.3,\n",
    "                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "assert len(train_queries_ids) / (len(train_queries_ids) + len(test_queries_ids)) == 0.6999123191582639"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > Теперь у нас есть:  \n",
    " 1) айдишники запросов для обучения и валидации **queries_id_train, queries_id_test**   \n",
    " 2) матрица данных **data**   \n",
    " 3) словарь **queries** с информацией о том, какие строчки в этой матрице соответствуют какому айдишнику  \n",
    " \n",
    " С помощью этих данных разделите матрицу data на матрицы **X_train, y_train, X_test, y_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [3, 3, 3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# изи пизи способ получить несколько строк матрицы по их id данные матрицы\n",
    "data_example = np.array(\n",
    "    [\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1],\n",
    "        [2, 2, 2],\n",
    "        [3, 3, 3]\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_example[[0, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиваем номера строк исходной матрицы на train и test\n",
    "\n",
    "train_queries_lines_info = [i for k in train_queries_ids for i in queries_lines_info[k]]\n",
    "test_queries_lines_info = [i for k in test_queries_ids for i in queries_lines_info[k]]\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train = data[train_queries_lines_info]\n",
    "y_train = labels[train_queries_lines_info]\n",
    "X_test = data[test_queries_lines_info]\n",
    "y_test = labels[test_queries_lines_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_queries_lines_info = np.array(train_queries_lines_info)\n",
    "test_queries_lines_info = np.array(test_queries_lines_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train.shape == (68418, 245) \n",
    "assert len(y_train) == 68418"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поздравляю, если вы все сделали до этого моменты, вы восхитительны! \n",
    "\n",
    "Данные готовы, можно заряжать модели                                                           \n",
    "Для оценивания качества моделей используйте метрику nDCG, реализованную ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics\n",
    "\n",
    "##test_lines = np.array(test_lines)\n",
    "\n",
    "\n",
    "def get_nDCG_score(queries, queries_lines_info, test_queries_lines_info, labels_true, labels_predicted):\n",
    "    nDCG_scores = [] # nDCG по каждому запросу\n",
    "    \n",
    "    for query in queries:\n",
    "        \n",
    "        query_lines = queries_lines_info[query]\n",
    "        query_lines_in_testdata = [np.where(test_queries_lines_info==line)[0][0] for line in query_lines]\n",
    "        \n",
    "        query_labels_true = labels_true[query_lines]\n",
    "        query_labels_pred = labels_predicted[query_lines_in_testdata]\n",
    "        \n",
    "        nDCG = metrics.ndcg_score(query_labels_true, query_labels_pred, k=10)\n",
    "        nDCG_scores.append(nDCG)\n",
    "        \n",
    "    nDCG_Queries = np.sum(nDCG_scores) / len(queries) # усредняем по всем запросам\n",
    "    return nDCG_Queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIT PREDICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Воспользовавшись известными вам техниками построения линейной регрессии, обучите модель, предсказывающую оценку асессора\n",
    "\n",
    "``` from sklearn.linear_model import LinearRegression``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "lin_reg_y_pred = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEsJJREFUeJzt3W2MXuWd3/HvbyFsttkHm2WgyHY6VGulYVcKoSPwCqnahdQYiGJaLRVRu7jIkvuCVom00tZpK1kLieS82TxIXSQruGu2aYibXYQVUNipQxStVB6GQEjAQfayXjwyxbO1IZuizYrk3xdzORnI2HPPzO25PVzfj3TrnPM/1zn3dckwvzmPk6pCktSfnxt1ByRJo2EASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjp14ag7cDaXXHJJjY+Pj7obkrSqPP30039TVWMLtTuvA2B8fJypqalRd0OSVpUkfz1IO08BSVKnFgyAJO9L8uycz/eTfDzJxUkmkxxu07WtfZJ8PsmRJM8luXrOvra19oeTbDuXA5Mknd2CAVBVL1bVVVV1FfBPgTeAB4GdwMGq2ggcbMsANwEb22cHcC9AkouBXcC1wDXArtOhIUlaeYs9BXQD8JdV9dfAVmBfq+8Dbm3zW4H7a9bjwJoklwM3ApNVdbKqTgGTwJZlj0CStCSLDYDbgS+1+cuq6hWANr201dcBx+ZsM91qZ6pLkkZg4ABIchHwEeB/LtR0nlqdpf7279mRZCrJ1MzMzKDdkyQt0mKOAG4CvlVVr7blV9upHdr0RKtPAxvmbLceOH6W+ltU1Z6qmqiqibGxBW9jlSQt0WIC4KP89PQPwAHg9J0824CH5tTvaHcDbQJeb6eIHgU2J1nbLv5ubjVJ0ggM9CBYkn8A/HPg380p7wb2J9kOvAzc1uqPADcDR5i9Y+hOgKo6meQe4KnW7u6qOrnsEUiSliTn8x+Fn5iYKJ8EXh3Gdz685G2P7r5liD2RlOTpqppYqJ1PAktSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqfO678JrJW1nKd5Ja0+HgFIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdGigAkqxJ8pUk30tyKMlvJrk4yWSSw226trVNks8nOZLkuSRXz9nPttb+cJJt52pQkqSFDXoE8Dnga1X1T4APAIeAncDBqtoIHGzLADcBG9tnB3AvQJKLgV3AtcA1wK7ToSFJWnkLBkCSXwb+GXAfQFX9fVW9BmwF9rVm+4Bb2/xW4P6a9TiwJsnlwI3AZFWdrKpTwCSwZaijkSQNbJAjgH8MzAD/LckzSb6Q5D3AZVX1CkCbXtrarwOOzdl+utXOVJckjcAgAXAhcDVwb1V9EPh//PR0z3wyT63OUn/rxsmOJFNJpmZmZgboniRpKQYJgGlguqqeaMtfYTYQXm2ndmjTE3Pab5iz/Xrg+Fnqb1FVe6pqoqomxsbGFjMWSdIiLBgAVfV/gGNJ3tdKNwAvAAeA03fybAMeavMHgDva3UCbgNfbKaJHgc1J1raLv5tbTZI0AoP+Scj/AHwxyUXAS8CdzIbH/iTbgZeB21rbR4CbgSPAG60tVXUyyT3AU63d3VV1ciijkCQt2kABUFXPAhPzrLphnrYF3HWG/ewF9i6mg5Kkc8MngSWpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1KmB/ii8dC6N73x4ydse3X3LEHsi9WWgI4AkR5N8J8mzSaZa7eIkk0kOt+naVk+Szyc5kuS5JFfP2c+21v5wkm3nZkiSpEEs5hTQb1fVVVU10ZZ3AgeraiNwsC0D3ARsbJ8dwL0wGxjALuBa4Bpg1+nQkCStvOVcA9gK7Gvz+4Bb59Tvr1mPA2uSXA7cCExW1cmqOgVMAluW8f2SpGUYNAAK+PMkTyfZ0WqXVdUrAG16aauvA47N2Xa61c5UlySNwKAXga+rquNJLgUmk3zvLG0zT63OUn/rxrMBswPgve9974DdkyQt1kBHAFV1vE1PAA8yew7/1XZqhzY90ZpPAxvmbL4eOH6W+tu/a09VTVTVxNjY2OJGI0ka2IIBkOQ9SX7p9DywGfgucAA4fSfPNuChNn8AuKPdDbQJeL2dInoU2Jxkbbv4u7nVJEkjMMgpoMuAB5Ocbv8/quprSZ4C9ifZDrwM3NbaPwLcDBwB3gDuBKiqk0nuAZ5q7e6uqpNDG4kkaVEWDICqegn4wDz1/wvcME+9gLvOsK+9wN7Fd1OSNGy+CkKSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1KlB/yi8VoHxnQ+PuguSVhGPACSpUwaAJHXKAJCkThkAktSpgQMgyQVJnkny1bZ8RZInkhxO8uUkF7X6z7flI239+Jx9fKLVX0xy47AHI0ka3GKOAD4GHJqz/GngM1W1ETgFbG/17cCpqvo14DOtHUmuBG4Hfh3YAvxRkguW131J0lINFABJ1gO3AF9oywGuB77SmuwDbm3zW9sybf0Nrf1W4IGq+mFV/RVwBLhmGIOQJC3eoEcAnwV+H/hxW/5V4LWqerMtTwPr2vw64BhAW/96a/+T+jzbSJJW2IIBkOTDwImqenpueZ6mtcC6s20z9/t2JJlKMjUzM7NQ9yRJSzTIEcB1wEeSHAUeYPbUz2eBNUlOP0m8Hjje5qeBDQBt/a8AJ+fW59nmJ6pqT1VNVNXE2NjYogckSRrMggFQVZ+oqvVVNc7sRdyvV9W/Bh4Dfqc12wY81OYPtGXa+q9XVbX67e0uoSuAjcCTQxuJJGlRlvMuoP8IPJDkk8AzwH2tfh/wJ0mOMPub/+0AVfV8kv3AC8CbwF1V9aNlfL8kaRkWFQBV9Q3gG23+Jea5i6eq/g647Qzbfwr41GI7KUkaPp8ElqROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnVowAJK8O8mTSb6d5Pkkf9DqVyR5IsnhJF9OclGr/3xbPtLWj8/Z1yda/cUkN56rQUmSFjbIEcAPgeur6gPAVcCWJJuATwOfqaqNwClge2u/HThVVb8GfKa1I8mVwO3ArwNbgD9KcsEwByNJGtyCAVCzftAW39U+BVwPfKXV9wG3tvmtbZm2/oYkafUHquqHVfVXwBHgmqGMQpK0aANdA0hyQZJngRPAJPCXwGtV9WZrMg2sa/PrgGMAbf3rwK/Orc+zzdzv2pFkKsnUzMzM4kckSRrIQAFQVT+qqquA9cz+1v7++Zq1ac6w7kz1t3/XnqqaqKqJsbGxQbonSVqCRd0FVFWvAd8ANgFrklzYVq0Hjrf5aWADQFv/K8DJufV5tpEkrbBB7gIaS7Kmzf8C8CHgEPAY8Dut2TbgoTZ/oC3T1n+9qqrVb293CV0BbASeHNZAJEmLc+HCTbgc2Nfu2Pk5YH9VfTXJC8ADST4JPAPc19rfB/xJkiPM/uZ/O0BVPZ9kP/AC8CZwV1X9aLjDkSQNasEAqKrngA/OU3+Jee7iqaq/A247w74+BXxq8d2UJA2bTwJLUqcMAEnqlAEgSZ0yACSpUwaAJHVqkNtApfPW+M6Hl7X90d23DKkn0urjEYAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdWjAAkmxI8liSQ0meT/KxVr84yWSSw226ttWT5PNJjiR5LsnVc/a1rbU/nGTbuRuWJGkhgxwBvAn8XlW9H9gE3JXkSmAncLCqNgIH2zLATcDG9tkB3AuzgQHsAq4FrgF2nQ4NSdLKWzAAquqVqvpWm/9b4BCwDtgK7GvN9gG3tvmtwP0163FgTZLLgRuByao6WVWngElgy1BHI0ka2KKuASQZBz4IPAFcVlWvwGxIAJe2ZuuAY3M2m261M9Xf/h07kkwlmZqZmVlM9yRJizBwACT5ReBPgY9X1ffP1nSeWp2l/tZC1Z6qmqiqibGxsUG7J0lapIECIMm7mP3h/8Wq+rNWfrWd2qFNT7T6NLBhzubrgeNnqUuSRmCQu4AC3Accqqo/nLPqAHD6Tp5twENz6ne0u4E2Aa+3U0SPApuTrG0Xfze3miRpBC4coM11wO8C30nybKv9J2A3sD/JduBl4La27hHgZuAI8AZwJ0BVnUxyD/BUa3d3VZ0cyigkSYu2YABU1V8w//l7gBvmaV/AXWfY115g72I6KEk6N3wSWJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdGuRtoFpB4zsfHnUXJHXCIwBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpxZ8ECzJXuDDwImq+o1Wuxj4MjAOHAX+VVWdShLgc8DNwBvAv62qb7VttgH/pe32k1W1b7hDkRZvOQ/eHd19yxB7Iq28QY4A/hjY8rbaTuBgVW0EDrZlgJuAje2zA7gXfhIYu4BrgWuAXUnWLrfzkqSlWzAAquqbwMm3lbcCp3+D3wfcOqd+f816HFiT5HLgRmCyqk5W1Slgkp8NFUnSClrqNYDLquoVgDa9tNXXAcfmtJtutTPVJUkjMuyLwJmnVmep/+wOkh1JppJMzczMDLVzkqSfWmoAvNpO7dCmJ1p9Gtgwp9164PhZ6j+jqvZU1URVTYyNjS2xe5KkhSw1AA4A29r8NuChOfU7MmsT8Ho7RfQosDnJ2nbxd3OrSZJGZJDbQL8E/BZwSZJpZu/m2Q3sT7IdeBm4rTV/hNlbQI8wexvonQBVdTLJPcBTrd3dVfX2C8uSpBW0YABU1UfPsOqGedoWcNcZ9rMX2Luo3kmSzhmfBJakThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnVrwddCS5je+8+Elb3t09y1D7Im0NB4BSFKnDABJ6pQBIEmd8hrAObCcc8OStFI8ApCkThkAktSpFT8FlGQL8DngAuALVbV7pfsgjZq3kOp8sKJHAEkuAP4rcBNwJfDRJFeuZB8kSbNW+gjgGuBIVb0EkOQBYCvwwgr3Q1q1PHrQsKx0AKwDjs1ZngauXeE+DMQ7efRONMr/rg2f889KB0DmqdVbGiQ7gB1t8QdJXjzL/i4B/mZIfTsfOJ7zm+NZhnz6nH+F/z4/9Y8GabTSATANbJizvB44PrdBVe0B9gyysyRTVTUxvO6NluM5vzme85vjWbyVvg30KWBjkiuSXATcDhxY4T5IkljhI4CqejPJvwceZfY20L1V9fxK9kGSNGvFnwOoqkeAR4a0u4FOFa0ijuf85njOb45nkVJVC7eSJL3j+CoISerUqg6AJLcleT7Jj5Os2qv/SbYkeTHJkSQ7R92f5UqyN8mJJN8ddV+WK8mGJI8lOdT+W/vYqPu0HEneneTJJN9u4/mDUfdpGJJckOSZJF8ddV+WK8nRJN9J8mySqXP5Xas6AIDvAv8S+OaoO7JU79DXY/wxsGXUnRiSN4Hfq6r3A5uAu1b5v88Pgeur6gPAVcCWJJtG3Kdh+BhwaNSdGKLfrqqr3mm3gQ5VVR2qqrM9KLYa/OT1GFX198Dp12OsWlX1TeDkqPsxDFX1SlV9q83/LbM/ZNaNtldLV7N+0Bbf1T6r+kJgkvXALcAXRt2X1WZVB8A7xHyvx1i1P2DeyZKMAx8EnhhtT5annS55FjgBTFbVqh4P8Fng94Efj7ojQ1LAnyd5ur0Z4Zw57/8iWJL/BfzDeVb956p6aKX7cw4s+HoMjV6SXwT+FPh4VX1/1P1Zjqr6EXBVkjXAg0l+o6pW5fWaJB8GTlTV00l+a9T9GZLrqup4kkuBySTfa0fVQ3feB0BVfWjUfTjHFnw9hkYrybuY/eH/xar6s1H3Z1iq6rUk32D2es2qDADgOuAjSW4G3g38cpL/XlX/ZsT9WrKqOt6mJ5I8yOxp4nMSAJ4CGj1fj3EeSxLgPuBQVf3hqPuzXEnG2m/+JPkF4EPA90bbq6Wrqk9U1fqqGmf2/52vr+Yf/knek+SXTs8DmzmH4byqAyDJv0gyDfwm8HCSR0fdp8WqqjeB06/HOATsX+2vx0jyJeB/A+9LMp1k+6j7tAzXAb8LXN9uy3u2/ba5Wl0OPJbkOWZ/+ZisqlV/6+Q7yGXAXyT5NvAk8HBVfe1cfZlPAktSp1b1EYAkaekMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOvX/AX1SXGbZLoJEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "h = plt.hist(lin_reg_y_pred, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем качество модели по метрике **nDCG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8277611333519912"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_lin_reg = get_nDCG_score(\n",
    "    queries = test_queries_ids, \n",
    "    queries_lines_info = queries_lines_info, \n",
    "    test_queries_lines_info = test_queries_lines_info, \n",
    "    labels_true = labels, \n",
    "    labels_predicted = lin_reg_y_pred\n",
    ")\n",
    " \n",
    "score_lin_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь решим эту задачу не как регрессию, а как классификацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7883605786516924"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lin_reg = LinearSVC()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "lin_reg_y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "score_lin_reg = get_nDCG_score(\n",
    "    queries = test_queries_ids, \n",
    "    queries_lines_info = queries_lines_info, \n",
    "    test_queries_lines_info = test_queries_lines_info, \n",
    "    labels_true = labels, \n",
    "    labels_predicted = lin_reg_y_pred\n",
    ")\n",
    " \n",
    "score_lin_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ранжируем с RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8246541103816422"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "rfr_y_pred = rfr.predict(X_test)\n",
    "\n",
    "score_rfr = get_nDCG_score(\n",
    "    queries = test_queries_ids, \n",
    "    queries_lines_info = queries_lines_info, \n",
    "    test_queries_lines_info = test_queries_lines_info, \n",
    "    labels_true = labels, \n",
    "    labels_predicted = rfr_y_pred\n",
    ")\n",
    "\n",
    "score_rfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ранжируем с XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7950120920703506"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbc = XGBClassifier()\n",
    "\n",
    "xgbc.fit(X_train, y_train)\n",
    "\n",
    "xgbc_y_pred = xgbc.predict(X_test)\n",
    "\n",
    "score_xgbc = get_nDCG_score(\n",
    "    queries = test_queries_ids, \n",
    "    queries_lines_info = queries_lines_info, \n",
    "    test_queries_lines_info = test_queries_lines_info, \n",
    "    labels_true = labels, \n",
    "    labels_predicted = xgbc_y_pred\n",
    ")\n",
    "\n",
    "score_xgbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ранжируем с LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044994458038927"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbmc = lightgbm.LGBMClassifier()\n",
    "\n",
    "gbmc.fit(X_train, y_train)\n",
    "\n",
    "gbmc_y_pred = gbmc.predict(X_test)\n",
    "\n",
    "score_gbmc = get_nDCG_score(\n",
    "    queries = test_queries_ids, \n",
    "    queries_lines_info = queries_lines_info, \n",
    "    test_queries_lines_info = test_queries_lines_info, \n",
    "    labels_true = labels, \n",
    "    labels_predicted = gbmc_y_pred\n",
    ")\n",
    "\n",
    "score_gbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
