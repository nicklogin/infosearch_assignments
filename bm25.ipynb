{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лекция 2  BM5    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{TF(q_i,D)*(k+1)}{TF(q_i,D)+k(1-b+b\\frac{l(d)}{avgdl})} $$ \n",
    "где   \n",
    ">$TF(q_i,D)$ - частота слова $q_i$ в документе $D$      \n",
    "$l(d)$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k$ и $b$ — свободные коэффициенты, обычно их выбирают как $k$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ - это модернизированная версия IDF: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "from math import log\n",
    "\n",
    "k = 2.0\n",
    "b = 0.75\n",
    "\n",
    "\n",
    "def bm25() -> float:\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 1__:    \n",
    "Напишите два поисковика на *BM25*. Один через подсчет метрики по формуле для каждой пары слово-документ, второй через умножение матрицы на вектор. \n",
    "\n",
    "Сравните время работы поиска на 100к запросах. В качестве корпуса возьмем \n",
    "[Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика точности: 1 - если в первой пятёрке документов есть хотя бы один документ - дубликат запроса, 0 - иначе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/quora_question_pairs_rus.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Какова история кохинор кох-и-ноор-бриллиант</td>\n",
       "      <td>что произойдет, если правительство Индии украд...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>как я могу увеличить скорость моего интернет-с...</td>\n",
       "      <td>как повысить скорость интернета путем взлома ч...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>почему я мысленно очень одинок, как я могу это...</td>\n",
       "      <td>найти остаток, когда математика 23 ^ 24 матема...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>которые растворяют в воде быстро сахарную соль...</td>\n",
       "      <td>какая рыба выживет в соленой воде</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>астрология: я - луна-колпачок из козерога и кр...</td>\n",
       "      <td>Я тройная луна-козерог и восхождение в козерог...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          question1  \\\n",
       "0           0        Какова история кохинор кох-и-ноор-бриллиант   \n",
       "1           1  как я могу увеличить скорость моего интернет-с...   \n",
       "2           2  почему я мысленно очень одинок, как я могу это...   \n",
       "3           3  которые растворяют в воде быстро сахарную соль...   \n",
       "4           4  астрология: я - луна-колпачок из козерога и кр...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  что произойдет, если правительство Индии украд...             0  \n",
       "1  как повысить скорость интернета путем взлома ч...             0  \n",
       "2  найти остаток, когда математика 23 ^ 24 матема...             0  \n",
       "3                  какая рыба выживет в соленой воде             0  \n",
       "4  Я тройная луна-козерог и восхождение в козерог...             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using hint from\n",
    "## https://stackoverflow.com/questions/43203215/map-unique-strings-to-integers-in-python\n",
    "def extract_texts(df):\n",
    "    question1 = list(set(df['question1']))\n",
    "    question2 = list(set(df['question2']))\n",
    "    mapping1 = {j:i for i,j in enumerate(question1)}\n",
    "    mapping2 = {j:i for i,j in enumerate(question2)}\n",
    "    df = df[df['is_duplicate']==1]\n",
    "    q1 = df['question1'].apply(lambda x: mapping1[x])\n",
    "    q2 = df['question2'].apply(lambda x: mapping2[x])\n",
    "    duplicate_matrix = csr_matrix((np.ones(df.shape[0]),\n",
    "                                  (q1,q2)),\n",
    "                                  shape=(len(question1),len(question2)))\n",
    "    return question1, question2, mapping1, mapping2, duplicate_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts1, texts2, text1_to_id, text2_to_id, duplicate_matrix = extract_texts(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Инициализация парсера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2.tokenizers import simple_word_tokenize as tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2.analyzer import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    return [parse.normal_form for parse in [analyzer.parse(word)[0] for word in tokenize(text)] if parse.tag.POS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['мир',\n",
       " 'замереть',\n",
       " 'в',\n",
       " 'ожидание',\n",
       " 'страшный',\n",
       " 'вещий',\n",
       " 'ты',\n",
       " 'слышать',\n",
       " 'голос',\n",
       " 'овощ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize('Мир замер в ожидании страшных вещей - ты слышишь голос овощей!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25 здорового человека:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMVectorSearch:\n",
    "    def __init__(self, docs, lemmatizer=lemmatize, k=2, b=0.75):\n",
    "        self.k = k\n",
    "        self.b = b\n",
    "        self.docs = []\n",
    "        self.lemmatizer = lemmatizer\n",
    "        self.update_index(docs)\n",
    "    \n",
    "    def update_index(self, docs):\n",
    "        self.docs = np.array(list(self.docs) + docs)\n",
    "        self.vectorizer = CountVectorizer(tokenizer=self.lemmatizer)\n",
    "        self.tf_matrix = self.vectorizer.fit_transform(self.docs)\n",
    "        ## counting non-zero values in sparse matrix row\n",
    "        ## using only sparse matrix operations:\n",
    "        ## dense matrix would be too big - 300+ GB (vs. ~500MB in sparse format)\n",
    "        df = self.tf_matrix.getnnz(axis=1)\n",
    "        N = df.sum()\n",
    "        idf_transform = np.vectorize(lambda x: (N-x+0.5)/(x+0.5))\n",
    "        self.idf = np.log(idf_transform(df))\n",
    "        self.set_hyperparams()\n",
    "    \n",
    "    def set_hyperparams(self, k=None, b=None):\n",
    "        if k is None:\n",
    "            k = self.k\n",
    "        else:\n",
    "            self.k = k\n",
    "        if b is None:\n",
    "            b = self.b\n",
    "        else:\n",
    "            self.b = b\n",
    "        doc_lengths = np.array(self.tf_matrix.sum(axis=0))[0]\n",
    "        avgdl = doc_lengths.mean()\n",
    "        length_ratios = np.array([doc_lengths[col]/avgdl for col in self.tf_matrix.nonzero()[1]])\n",
    "        idfs = np.array([self.idf[row] for row in self.tf_matrix.nonzero()[0]])\n",
    "        new_data = idfs * self.tf_matrix.data * (k+1) / (self.tf_matrix.data + k*(1-b+b*length_ratios))\n",
    "        self.index = csr_matrix((new_data, self.tf_matrix.indices, self.tf_matrix.indptr),\n",
    "                                shape=self.tf_matrix.shape)\n",
    "        self.index = self.index.transpose(copy=True)\n",
    "    \n",
    "    def search(self, query, return_similarities=False, return_indices=False, n_results=5):\n",
    "        vector = self.vectorizer.transform([query])\n",
    "        similarities = vector * self.index\n",
    "        similarities = np.array(similarities.todense())[0]\n",
    "        order = np.argsort(similarities)[::-1].tolist()[:n_results]\n",
    "        \n",
    "        if return_similarities:\n",
    "            if return_indices:\n",
    "                return similarities[order], order\n",
    "            return similarities[order], self.docs[order]\n",
    "        \n",
    "        if return_indices:\n",
    "            return order\n",
    "        return self.docs[order]\n",
    "    \n",
    "    def multiple_search(self, query):\n",
    "        vector = self.vectorizer.transform(query)\n",
    "        return vector * self.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global search\n",
    "search = BMVectorSearch(texts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 71.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['что означает dlc для ps4, означает, что область, запертая в области dlc, означает',\n",
       "       'то, что означает эпидермальный фактор роста, означает, что факторы роста, вызванные тромбоцитами, означают',\n",
       "       'в instagram под увеличительным стеклом - что означает верхняя часть означает, что это означает, что я обыскал, что Instagram счета наиболее',\n",
       "       'что означает слово «презрение» означает ли это только означает рассматривать с презрением и презрением или может также использоваться как синоним ненависти',\n",
       "       'что означает, что название quora означает'], dtype='<U1283')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "search.search('что означает')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for text in texts1[:100]:\n",
    "    search.search(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 запросов обработались за 6.72 с - 100000 обработаются за 6720 с - примерно 2 часа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25 курильщика:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25Naive:\n",
    "    def __init__(self, docs, lemmatizer=lemmatize, k=2, b=0.75):\n",
    "        self.k, self.b = k, b\n",
    "        self.lemmatize = lemmatizer\n",
    "        self.docs = docs\n",
    "        docs = [self.lemmatize(i) for i in self.docs]\n",
    "        self.index = []\n",
    "        df = defaultdict(int)\n",
    "        for doc in docs:\n",
    "            freq_dict = dict()\n",
    "            for word in set(doc):\n",
    "                freq_dict[word] = doc.count(word)\n",
    "                df[word] += 1\n",
    "            self.index.append(freq_dict)\n",
    "        N = len(docs)\n",
    "        lengths = [len(i) for i in self.index]\n",
    "        self.avgdl = sum(lengths)/N\n",
    "        self.idf = {word: log((N-freq+0.5)/(freq+0.5)) for word, freq in df.items()}\n",
    "    \n",
    "    def search(self, query, n_results=5):\n",
    "        query = self.lemmatize(query)\n",
    "        similarities = []\n",
    "        for doc in self.index:\n",
    "            similarity = 0\n",
    "            for word in query:\n",
    "                if word in doc:\n",
    "                    similarity += self.idf[word]*((doc[word]*(self.k+1))/(doc[word]+\\\n",
    "                                                                          self.k*(1-self.b+self.b*len(doc)/self.avgdl)))\n",
    "                else:\n",
    "                    pass\n",
    "            similarities.append(similarity)\n",
    "            \n",
    "        #print(similarities)\n",
    "        \n",
    "        return sorted(list(enumerate(self.docs)), key=lambda x: similarities[x[0]],\n",
    "                     reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global search1\n",
    "search1 = BM25Naive(texts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучилась примерно за такое же время, что и векторизованная - 8 минут. Посмотрим, насколько быстр поиск:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 243 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(31346, 'что действительно означает, что означает'),\n",
       " (160419, 'что это означает, что означает'),\n",
       " (223470, 'что означает, что название quora означает'),\n",
       " (184695,\n",
       "  'что означает dlc для ps4, означает, что область, запертая в области dlc, означает'),\n",
       " (24301, 'что это означает, что логотип microsoft означает')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "search1.search('что означает')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для одного запроса время поиска в 4 раза дольше. Попробуем 100 запросов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for text in texts1[:100]:\n",
    "    search1.search(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 запросов обработались за ~40 сек, значит 100000 запросов обработаются за 40000 сек - более 10 часов. Так как время = деньги, не будем этого делать :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 2__:    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите 10 первых результатов и их близость по метрике BM25 по запросу **рождественские каникулы** на нашем корпусе  Quora question pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([23.83887156, 23.09006036, 19.40935756, 14.74838683, 14.52495889,\n",
       "        14.44521674, 14.33895981, 14.33895981, 14.33895981, 14.33895981]),\n",
       " array(['как долго проходят рождественские каникулы для университетов в Новой Зеландии',\n",
       "        'какое лучшее место для посещения во время рождественских каникул из Лондона на 3 - 4 дня для одного путешественника',\n",
       "        'какие рождественские традиции вы и ваша семья имеете на рождественский вечер и рождественский день',\n",
       "        'каков ваш обзор каникул',\n",
       "        'какова политика каникул google для сотрудников',\n",
       "        'какой продукт привлекателен в качестве рождественских подарков, я хочу, чтобы некоторые продукты были представлены как маленькие рождественские подарки, которые могут привлечь молодых людей, я собираюсь продавать какую-то индивидуальную электронику в Интернете и продавать их на Рождество',\n",
       "        'когда каникулы даются на iits для курсов btech',\n",
       "        'какие хорошие семейные каникулы в Керале',\n",
       "        'у каникул есть сцены с комментариями',\n",
       "        'что означает отсутствие политики каникул в d e shaw'],\n",
       "       dtype='<U1283'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.search('рождественские каникулы',\n",
    "                     return_similarities=True, n_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 3__:    \n",
    "\n",
    "Посчитайте точность поиска при \n",
    "1. BM25, b=0.75 \n",
    "2. BM15, b=0 \n",
    "3. BM11, b=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## слишком долго работает, придумать что-нибудь для ускорения:\n",
    "def evaluate(search_engine, texts, duplicate_matrix, test_size=10000):\n",
    "    s = 0\n",
    "    N = 0\n",
    "    \n",
    "    random.seed(42)\n",
    "    texts = random.choices(list(enumerate(texts)), k=test_size)\n",
    "    \n",
    "    for text_id, text in texts:\n",
    "        if duplicate_matrix[text_id,].sum():\n",
    "            N += 1\n",
    "            results = search_engine.search(text, return_indices=True)\n",
    "            for result_id in results:\n",
    "                if duplicate_matrix[text_id,result_id]:\n",
    "                    s += 1\n",
    "                    break\n",
    "    return s/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_evaluate(search_engine, texts, duplicate_matrix, test_size=100000):\n",
    "    N = 0\n",
    "    s = 0\n",
    "    random.seed(42)\n",
    "    texts = random.choices(list(enumerate(texts)), k=test_size)\n",
    "    texts = [i[1] for i in texts]\n",
    "    sims = search_engine.multiple_search(texts)\n",
    "    for row_id, text_id, text in zip(range(test_size), ids, texts):\n",
    "        if duplicate_matrix[text_id,].sum():\n",
    "            N += 1\n",
    "            ## add something...\n",
    "    return s/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM25, b=0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39019337016574585"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "evaluate(search, texts1, duplicate_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM15, b=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "BMVectorSearch.set_hyperparams(search, b=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3349447513812155"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(search, texts1, duplicate_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM11, b=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37465469613259667"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BMVectorSearch.set_hyperparams(search, b=1)\n",
    "evaluate(search, texts1, duplicate_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Вывод</b>: Наилучшее качество поиска достигается при b=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
