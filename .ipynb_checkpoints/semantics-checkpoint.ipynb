{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec + fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если модель без тэгов\n",
    "model_file = '../data/araneum_none_fasttextcbow_300_5_2018/araneum_none_fasttextcbow_300_5_2018.model'\n",
    "\n",
    "# model = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если модель с POS-тэггингом\n",
    "model_file = '../data/tayga.vec'\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(model_file, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "проверка наличия слова в словаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = 'черепаха_NOUN'\n",
    "lemma in model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получение вектора слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.wv[lemma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model[lemma]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получение вектора документа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if sys.path[0] == '':\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# сделали препроцессинг, получили леммы \n",
    "lemmas = ['старинный_ADJ', 'замок_NOUN']\n",
    "\n",
    "# создаем маски для векторов \n",
    "lemmas_vectors = np.zeros((len(lemmas), model.vector_size))\n",
    "vec = np.zeros((model.vector_size,))\n",
    "\n",
    "# если слово есть в модели, берем его вектор\n",
    "for idx, lemma in enumerate(lemmas):\n",
    "    if lemma in model.wv:\n",
    "        lemmas_vectors[idx] = model.wv[lemma]\n",
    "        \n",
    "# проверка на случай, если на вход пришел пустой массив\n",
    "if lemmas_vectors.shape[0] is not 0:\n",
    "    vec = np.mean(lemmas_vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте поиск по [Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian) на нескольких векторных моделях\n",
    "\n",
    "    1. fasttext, модель ruscorpora_none_fasttextskipgram_300_2_2019\n",
    "    2. elmo, модель ruwikiruscorpora_lemmas_elmo_1024_2019\n",
    "    3. bert*, RuBERT - необязательно\n",
    "   \n",
    "Первые две обученные модели можно скачать на сайте [rusvectores](https://rusvectores.org/en/models/).\n",
    "\n",
    "BERT делать необязательно, но если сделаете, 6 за курс у вас автоматом. Модель можно [найти тут](http://docs.deeppavlov.ai/en/master/features/models/bert.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/quora_question_pairs_rus.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Какова история кохинор кох-и-ноор-бриллиант</td>\n",
       "      <td>что произойдет, если правительство Индии украд...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>как я могу увеличить скорость моего интернет-с...</td>\n",
       "      <td>как повысить скорость интернета путем взлома ч...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>почему я мысленно очень одинок, как я могу это...</td>\n",
       "      <td>найти остаток, когда математика 23 ^ 24 матема...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>которые растворяют в воде быстро сахарную соль...</td>\n",
       "      <td>какая рыба выживет в соленой воде</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>астрология: я - луна-колпачок из козерога и кр...</td>\n",
       "      <td>Я тройная луна-козерог и восхождение в козерог...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          question1  \\\n",
       "0           0        Какова история кохинор кох-и-ноор-бриллиант   \n",
       "1           1  как я могу увеличить скорость моего интернет-с...   \n",
       "2           2  почему я мысленно очень одинок, как я могу это...   \n",
       "3           3  которые растворяют в воде быстро сахарную соль...   \n",
       "4           4  астрология: я - луна-колпачок из козерога и кр...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  что произойдет, если правительство Индии украд...             0  \n",
       "1  как повысить скорость интернета путем взлома ч...             0  \n",
       "2  найти остаток, когда математика 23 ^ 24 матема...             0  \n",
       "3                  какая рыба выживет в соленой воде             0  \n",
       "4  Я тройная луна-козерог и восхождение в козерог...             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using hint from\n",
    "## https://stackoverflow.com/questions/43203215/map-unique-strings-to-integers-in-python\n",
    "def extract_texts(df):\n",
    "    df = df.dropna()\n",
    "    question1 = list(set(df['question1']))\n",
    "    question2 = list(set(df['question2']))\n",
    "    mapping1 = {j:i for i,j in enumerate(question1)}\n",
    "    mapping2 = {j:i for i,j in enumerate(question2)}\n",
    "    df = df[df['is_duplicate']==1]\n",
    "    q1 = df['question1'].apply(lambda x: mapping1[x])\n",
    "    q2 = df['question2'].apply(lambda x: mapping2[x])\n",
    "    duplicate_matrix = csr_matrix((np.ones(df.shape[0]),\n",
    "                                  (q1,q2)),\n",
    "                                  shape=(len(question1),len(question2)))\n",
    "    return question1, question2, mapping1, mapping2, duplicate_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts1, texts2, text1_to_id, text2_to_id, duplicate_matrix = extract_texts(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Инициализация парсера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2.tokenizers import simple_word_tokenize as tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2.analyzer import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    return [parse.normal_form for parse in [analyzer.parse(word)[0] for word in tokenize(text)] if parse.tag.POS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['мир',\n",
       " 'замереть',\n",
       " 'в',\n",
       " 'ожидание',\n",
       " 'страшный',\n",
       " 'вещий',\n",
       " 'ты',\n",
       " 'слышать',\n",
       " 'голос',\n",
       " 'овощ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize('Мир замер в ожидании страшных вещей - ты слышишь голос овощей!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 1__:    \n",
    "Сравните время индексации корпуса для каждой модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = KeyedVectors.load('models/fasttext/model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sys.path.append('simple_elmo')\n",
    "from elmo_helpers import load_elmo_embeddings, get_elmo_vectors\n",
    "\n",
    "tf.reset_default_graph()\n",
    "elmo_path = 'models/elmo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [lemmatize(i) for i in \n",
    "            ('мир замер в ожидании жутких вещей',\n",
    "            'я слышу голос овощей')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From simple_elmo\\bilm\\model.py:522: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From simple_elmo\\bilm\\model.py:567: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "encoding new sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentences in this batch: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.168900728225708\n"
     ]
    }
   ],
   "source": [
    "# Loading a pre-trained ELMo model:\n",
    "batcher, sentence_character_ids, elmo_sentence_input = load_elmo_embeddings(elmo_path)\n",
    "\n",
    "\n",
    "# Actually producing ELMo embeddings for our data:\n",
    "with tf.Session() as sess:\n",
    "    print('encoding new sentences...')\n",
    "    # It is necessary to initialize variables once before running inference.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    start = time.time()\n",
    "    elmo_vectors = get_elmo_vectors(\n",
    "        sess, sentences, batcher, sentence_character_ids, elmo_sentence_input)\n",
    "    print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6, 1024)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(elmo_sentence_input['weighted_op'].shape[2].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(elmo_vectors, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим класс для поиска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2VSearch:\n",
    "    def __init__(self, model, texts, lemmatizer=lemmatize):\n",
    "        self.texts = np.array(texts)\n",
    "        self.model = model\n",
    "        self.lemmatize = lemmatizer\n",
    "        self.index = np.zeros(shape=(len(texts),model.vector_size))\n",
    "        for text_id, text in enumerate(texts):\n",
    "            if text:\n",
    "                self.index[text_id] = self.transform(text)\n",
    "        self.texts = self.texts[~np.isnan(self.index).any(axis=1)]\n",
    "        self.index = self.index[~np.isnan(self.index).any(axis=1)]\n",
    "        self.index = normalize(self.index)\n",
    "        self.index = self.index.transpose() \n",
    "    \n",
    "    def transform(self, text):\n",
    "        vecs = [self.model[word] for word in self.lemmatize(text) if word in self.model]\n",
    "        if vecs:\n",
    "            return np.mean(vecs, axis=0)\n",
    "    \n",
    "    def search(self, text, return_indices=False, n_results=5):\n",
    "        query = normalize(self.transform(text)[np.newaxis])\n",
    "        sims = np.dot(query, self.index)\n",
    "        top_texts = np.argsort(sims[0]).tolist()[::-1]\n",
    "        top_texts = top_texts[:n_results]\n",
    "        if return_indices:\n",
    "            return top_texts\n",
    "        else:\n",
    "            return self.texts[top_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global search\n",
    "search = W2VSearch(ft_model, texts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300) (300, 296683)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['кто такие дети', 'кто такой harsha bhogle',\n",
       "       'кто такой jose mourinho', 'кто такой karl marx',\n",
       "       'кто такой шив-надар'], dtype='<U1283')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2VSearch.search(search, 'кто такие фиксики')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300) (300, 296683)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['лучший рецепт японского жареного риса', 'лучший рецепт сэндвича',\n",
       "       'лучший рецепт печеного картофеля',\n",
       "       'какие хорошие приправы добавить к рецепту картофельного пюре',\n",
       "       'какие лучшие заменители лука-порея в рецепте супа'],\n",
       "      dtype='<U1283')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2VSearch.search(search, 'рецепт макарон по-клингонски')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим класс для поиска по модели elmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmoSearch:\n",
    "    def __init__(self, texts, batcher, sentence_character_ids, elmo_sentence_input, tensor_size=20):\n",
    "        self.texts = np.array(texts)\n",
    "        self.batcher = batcher\n",
    "        self.scids = sentence_character_ids\n",
    "        self.esi = elmo_sentence_input\n",
    "        self.index = np.zeros(shape=(len(texts),elmo_sentence_input['weighted_op'].shape[2].value))\n",
    "        for i in range(0, len(self.texts), tensor_size):\n",
    "            j = min(i+tensor_size, len(self.texts))\n",
    "            self.index[i:j] = self.transform(self.texts[i:j])\n",
    "        self.texts = self.texts[~np.isnan(self.index).any(axis=1)]\n",
    "        self.index = self.index[~np.isnan(self.index).any(axis=1)]\n",
    "        self.index = normalize(self.index)\n",
    "        self.index = self.index.transpose()\n",
    "    \n",
    "    def transform(self, texts):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            elmo_vectors = get_elmo_vectors(\n",
    "                sess, texts, self.batcher, self.scids, self.esi)\n",
    "            return np.mean(elmo_vectors, axis=1)\n",
    "        \n",
    "    def search(self, text, return_indices=False, n_results=5):\n",
    "        query = normalize(self.transform([text]))\n",
    "        sims = np.dot(query, self.index)\n",
    "        top_texts = np.argsort(sims[0]).tolist()[::-1]\n",
    "        top_texts = top_texts[:n_results]\n",
    "        if return_indices:\n",
    "            return top_texts\n",
    "        else:\n",
    "            return self.texts[top_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentences in this batch: 1\n",
      "Sentences in this batch: 1\n",
      "Sentences in this batch: 1\n",
      "Sentences in this batch: 1\n",
      "Sentences in this batch: 1\n",
      "Sentences in this batch: 1\n",
      "Sentences in this batch: 1\n",
      "Sentences in this batch: 1\n",
      "Sentences in this batch: 1\n",
      "Sentences in this batch: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global search_elmo\n",
    "search_elmo = ElmoSearch(texts2[:10], batcher, sentence_character_ids, elmo_sentence_input, tensor_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296807"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-c13a8816bf54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "tf.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function global_variables_initializer in module tensorflow.python.ops.variables:\n",
      "\n",
      "global_variables_initializer()\n",
      "    Returns an Op that initializes global variables.\n",
      "    \n",
      "    This is just a shortcut for `variables_initializer(global_variables())`\n",
      "    \n",
      "    Returns:\n",
      "      An Op that initializes global variables in the graph.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.global_variables_initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 2__:    \n",
    "Выведите качество поиска для каждой модели +  BM25 для сравнения\n",
    "\n",
    "Качество оцениваем так же, как в прошлом задании:\n",
    "    - если в топ-5 результатов выдачи попал хоть один релевантный документ, выдача точная\n",
    "    - если в топ-5 нет ни одного релеватного документа, выдача получает 0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(search_engine, texts, duplicate_matrix, test_size=10000):\n",
    "    s = 0\n",
    "    N = 0\n",
    "    \n",
    "    random.seed(42)\n",
    "    texts = random.choices(list(enumerate(texts)), k=test_size)\n",
    "    \n",
    "    for text_id, text in texts:\n",
    "        if duplicate_matrix[text_id,].sum():\n",
    "            N += 1\n",
    "            results = search_engine.search(text, return_indices=True)\n",
    "            for result_id in results:\n",
    "                if duplicate_matrix[text_id,result_id]:\n",
    "                    s += 1\n",
    "                    break\n",
    "    return s/N    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = np.zeros(shape=(288030,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
